On another side, early time series classification is also a classification problem which considers the temporal nature of data,
but with a slightly different objective and used for different scenarios other than time series classification.\newline
eTSC's main objective is to learn a model which can classify unseen instances as early as possible,
while maintaining a competitive accuracy compared to a model that uses full length data or to a user defined threshold\cite{xing2009early}.
Which is a very challenging objective; due to the, naturally, contradicting nature of earliness and accuracy.
In general, the more data is made available for the model to learn the better accuracy it can attain \cite{mori2019early,tavenard2016cost,xing2012early,mori2017reliable}.
This is why many eTSC researches consider it as a problem of optimizing multiple objectives.\newline
eTSC is needed in situations in which waiting for more data to arrive can be costly or
when making late decisions can cause unfavorable results \cite{mori2017early,parrish2013classifying,lin2015reliable}.
This is why eTSC has been applied in various domains like early medical diagnosis \cite{griffin2001toward,ghalwash2012early},
avoiding issues in network traffic flow \cite{bernaille2006traffic}, human activity recognition \cite{yazdanbakhsh2019multivariate,gupta2020fault}
and early prediction of stock crisis \cite{ghalwash2014utilizing}.\newline
We follow the definition of earliness mentioned by \cite{schafer2020teaser}; as the mean number of data points s after which a label is assigned.
\begin{definition}
    $Earliness = \frac{\sum_{T{i}\in D} \frac{s}{len(T{i})} }{|D|}$
\end{definition}
As well as the objective measure, Harmonic mean (HM), mentioned by \cite{ghalwash2012early,schafer2020teaser}, which includes both accuracy and earliness.
For the problem we have, HM is a weighted average between accuracy and earliness.
\begin{definition}
    $F_{\beta} = (1 + \beta^2)\frac{accuracy(1-earliness)}{\beta^2(1-accuracy)+earliness}$
\end{definition}
The value of $\beta$ can be used to give higher importance to one of the aspects over the other, but we use equal weights for both.